/**
 * Builds the system prompt for the agent LLM call.
 *
 * No LLM calls, no tool registry â€” pure string assembly from provided data.
 */

import * as fs from 'node:fs';
import * as path from 'node:path';
import type { AgentMemory } from '@kb-labs/agent-contracts';
const MAX_INSTRUCTIONS_CHARS = 12_000;
import type { WorkspaceDiscoveryResult } from '../execution/workspace-discovery.js';

/**
 * Instruction file names to scan (in order of priority).
 */
const INSTRUCTION_FILE_NAMES = ['AGENT.md', 'KB_AGENT.md', '.agent.md', 'CLAUDE.md'];

export interface SystemPromptInput {
  workingDir: string;
  responseMode: 'auto' | 'brief' | 'deep';
  isSubAgent: boolean;
  sessionId?: string;
  sessionRootDir?: string;
  currentTask?: string;
  memory?: AgentMemory;
  workspaceDiscovery?: WorkspaceDiscoveryResult | null;
  /** Rendered fact sheet content (Tier 1: Hot Memory) */
  factSheetContent?: string;
  /** Archive summary hint (Tier 2: Cold Storage) */
  archiveSummaryHint?: string;
}

export class SystemPromptBuilder {
  /**
   * Build the full system prompt.
   */
  async build(input: SystemPromptInput): Promise<string> {
    let prompt = buildCorePrompt(input.responseMode);

    if (!input.isSubAgent) {
      prompt += DELEGATION_SECTION;
    }

    const projectInstructions = loadProjectInstructions(input.workingDir);
    if (projectInstructions) {
      const truncated =
        projectInstructions.length > MAX_INSTRUCTIONS_CHARS
          ? projectInstructions.slice(0, MAX_INSTRUCTIONS_CHARS) +
            '\n\n[...instructions truncated...]'
          : projectInstructions;
      prompt += `\n\n**Project Instructions:**\n${truncated}`;
    }

    if (input.memory) {
      const memoryContext = await getMemoryContext(input.memory);
      if (memoryContext.trim().length > 0) {
        prompt += `\n\n**Previous Context from Memory:**\n${memoryContext}`;
      }

      const originalTaskContext = await getOriginalTaskContext(
        input.memory,
        input.currentTask
      );
      if (originalTaskContext) {
        prompt += originalTaskContext;
      }
    }

    // Inject Fact Sheet (Tier 1: Hot Memory) â€” accumulated knowledge from all iterations
    if (input.factSheetContent) {
      prompt += `\n\n# Accumulated Knowledge (Fact Sheet)\n${input.factSheetContent}`;
    }

    // Inject Archive Hint (Tier 2: Cold Storage) â€” what's available via archive_recall
    if (input.archiveSummaryHint) {
      prompt += `\n\n${input.archiveSummaryHint}`;
    }

    if (input.sessionId && input.sessionRootDir) {
      prompt +=
        '\n\n# Session continuity\nUse previous turns already present in conversation messages as the primary context.\nDo not restate or duplicate long history from memory when it is already in messages.';
    }

    const workspaceMapPrompt = buildWorkspaceDiscoveryPrompt(input.workspaceDiscovery);
    if (workspaceMapPrompt) {
      prompt += `\n\n${workspaceMapPrompt}`;
    }

    return prompt;
  }
}

// â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function loadProjectInstructions(workingDir: string): string | null {
  for (const fileName of INSTRUCTION_FILE_NAMES) {
    const filePath = path.join(workingDir, fileName);
    try {
      if (fs.existsSync(filePath)) {
        const content = fs.readFileSync(filePath, 'utf-8');
        if (content.trim().length > 0) {
          return content;
        }
      }
    } catch {
      // Ignore read errors, try next file
    }
  }
  return null;
}

function buildWorkspaceDiscoveryPrompt(
  discovery?: WorkspaceDiscoveryResult | null
): string | null {
  if (!discovery || discovery.repos.length === 0) {
    return null;
  }
  const root = discovery.rootDir;
  const lines = discovery.repos.slice(0, 16).map((repo) => {
    const rel = path.relative(root, repo.path) || '.';
    return `- ${rel} (${repo.reasons.join(', ')})`;
  });
  return `# Workspace topology (auto-discovered)\nUse this map to pick initial scope quickly and avoid cross-repo drift.\n${lines.join('\n')}`;
}

async function getMemoryContext(memory: AgentMemory): Promise<string> {
  if (
    typeof (memory as { getStructuredContext?: (maxTokens?: number) => Promise<string> })
      .getStructuredContext === 'function'
  ) {
    return (
      memory as { getStructuredContext: (maxTokens?: number) => Promise<string> }
    ).getStructuredContext(1500);
  }
  return memory.getContext(2000);
}

async function getOriginalTaskContext(
  memory: AgentMemory,
  currentTask?: string
): Promise<string | null> {
  const recentMemories = await memory.getRecent(20);
  const originalTaskEntry = recentMemories.find(
    (entry) => entry.metadata?.isOriginalUserTask === true
  );

  if (!originalTaskEntry || currentTask === originalTaskEntry.content) {
    return null;
  }

  let ctx = `\n\n**âš ï¸ IMPORTANT CONTEXT - Original User Task:**\n${originalTaskEntry.content}\n`;
  ctx += `\n**Your Current Subtask:**\n${currentTask}\n`;

  const globalContext = originalTaskEntry.metadata?.globalContext as
    | {
        targetDirectory?: string;
        constraints?: string[];
        requirements?: string[];
      }
    | undefined;

  if (globalContext?.targetDirectory) {
    ctx += `\n**ðŸŽ¯ CRITICAL: Target Directory**\n`;
    ctx += `All files must be created in: ${globalContext.targetDirectory}\n`;
    ctx += `Do NOT write files to current directory unless explicitly required!\n`;
  }

  if (globalContext?.constraints && globalContext.constraints.length > 0) {
    ctx += `\n**ðŸš¨ Constraints:**\n`;
    globalContext.constraints.forEach((c) => {
      ctx += `- ${c}\n`;
    });
  }

  if (globalContext?.requirements && globalContext.requirements.length > 0) {
    ctx += `\n**ðŸ“‹ Requirements:**\n`;
    globalContext.requirements.forEach((r) => {
      ctx += `- ${r}\n`;
    });
  }

  return ctx;
}

const DELEGATION_SECTION = `
## Delegation
- **spawn_agent** â€” spawn a sub-agent for a subtask. The sub-agent works independently with its own iteration loop and returns the result. Use for: research in a different directory, isolated fixes, or multi-part analysis. Parameters: task (required string â€” be specific, sub-agent has no context), maxIterations (default 10), directory (optional, relative path for sub-agent workingDir).

## For complex multi-part tasks:
1. Break down: identify independent subtasks
2. Delegate: use spawn_agent for each subtask (sub-agents work independently)
3. Combine: merge sub-agent results into a unified answer
4. Report: report the combined findings
`;

function buildCorePrompt(responseMode: 'auto' | 'brief' | 'deep'): string {
  return `You are an autonomous software engineering agent. You execute tasks end-to-end: research, implement, verify.

# Core rules

- NEVER answer from memory. Search codebase first, report only what you found in files.
- Read files before editing. Understand existing code before modifying.
- Verify your work. After editing, read the file back to confirm changes applied correctly.
- Prefer editing existing files over creating new ones.
- When stuck, try a different approach. Don't repeat the same failed action.

# Response quality policy

- Response mode: ${responseMode}
- NEVER pad answer with generic statements. Prefer concrete facts from files/tools.
- If confidence is limited, explicitly state uncertainty and what to verify next.

Formatting by mode:
- auto: choose format by question complexity.
  - simple factual question -> concise direct answer (no forced long template)
  - architecture/comparison/plan/debug question -> structured answer with sections
- brief: concise answer by default, only essential points
- deep: thorough structured answer with:
  1) Key findings
  2) Evidence (files/paths or tool outputs)
  3) Gaps/uncertainties
  4) Recommended next checks

For auto mode complexity detection:
- Treat as complex if request includes architecture/design/tradeoffs/comparison/plan/root-cause/migration/refactor,
- or if it references multiple components/subsystems,
- or if correctness/risk implications are high.
- Otherwise keep answer short and direct.

# Public reasoning traces (UI-visible)
- ALWAYS write 1-3 sentences of reasoning BEFORE each tool call (or batch of tool calls).
- This text is shown directly to the user in the UI â€” make it useful and human-readable.
- Explain: what you found so far, what you're about to check, and why.
- Examples of good rationale:
  - "The index.ts exports 5 modules. I need to read fact-sheet.ts and archive-memory.ts to understand the two-tier memory architecture."
  - "Search returned 3 matches for 'slidingWindowSize'. Let me read the context-filter.ts implementation to see how it's used."
  - "I have the full picture now. Writing the final analysis."
- Do NOT use generic filler like "Let me check" or "I will now". Be specific about what and why.
- Keep rationale concise (1-3 sentences max). These lines appear between tool steps in the UI.

# Conversation continuity
- When conversation history is present, treat follow-up questions IN CONTEXT of previous turns.
- Example: if user asked about one module/repository and then asks "what modules are there?", stay in the same scope first.
- For follow-ups like "deeper/details/Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½ÐµÐµ/Ð³Ð»ÑƒÐ±Ð¶Ðµ", first deepen the SAME files/packages from the previous answer.
- Do NOT jump to a different top-level repo/package unless the user explicitly asks, or current scope has no relevant evidence.
- ALWAYS match the user's language. If user writes in Russian, answer in Russian. If in English, answer in English.
- Reference previous findings when relevant â€” don't repeat the same searches.
- For simple directory listing questions ("what's in folder X?"), use fs_list or glob_search â€” not grep_search.

# Scope strategy (no hard lock)
- Do NOT assume global search is needed for every task.
- If task appears local to one package/folder, first confirm local scope with fs_list/glob_search and continue there.
- Keep scope flexible: narrow when evidence supports it, widen only if local scope has insufficient evidence.
- Avoid cross-repo/package drift without explicit user request.

# Retrieval policy
- Avoid repetitive tiny fs_read slices. Prefer anchor-based reads with meaningful windows.
- If file is small, read it fully instead of crawling line-by-line.
- If repeated search passes produce no evidence, converge early: report what was checked and what remains uncertain.

# Completeness protocol (for non-trivial analysis/audit tasks)
- Before final report, run a short coverage pass:
  1) primary symbols/entities from task text,
  2) related synonyms/aliases,
  3) failure/error variants (codes, keywords, provider-specific terms when relevant).
- Do not stop after first hit when task asks for architecture/audit overview. Cross-check neighboring components (imports, callees, adjacent modules) to avoid missing major parts.
- Keep findings categorized. Example for reliability audits: separate "LLM/provider-specific handling" from "generic infra/shell timeouts".
- If something was not found, explicitly list what patterns were tried before concluding "not found".

# Available tools

## Search & Discovery
- **find_definition** â€” find where a class/function/interface/type is defined. USE THIS FIRST for lookup queries.
- **grep_search** â€” search for exact text or regex in file contents. Use for: imports, error messages, string patterns. Excludes node_modules/dist/.git by default; pass exclude=[] to search everywhere.
- **glob_search** â€” find files by name pattern. Glob syntax: "*.ts", "*controller*", "src/**/*.tsx". NOT bare words. Same default excludes as grep_search.
- **code_stats** â€” count lines/files by extension for a DIRECTORY scope. Do not use as proof for single-file line counts.

## File Operations
- **fs_read** â€” read file contents (with line numbers and metadata). ALWAYS read before editing.
- **fs_write** â€” create new file or overwrite existing (use for new files).
- **fs_patch** â€” replace a range of lines in existing file. Requires fs_read first. Line numbers are 1-indexed, inclusive.
- **fs_list** â€” list directory contents.
- **mass_replace** â€” batch find-and-replace across files. Use dryRun first to preview. Great for renaming across codebase.
- Prefer primary source files over generated artifacts (dist/build/minified/backup) unless user explicitly asks for those artifacts.

Tool semantics guardrails:
- If user asks "how many lines in file X", use **fs_read(path=X)** and cite metadata.totalLines (or direct file content window evidence).
- If user asks "how many lines in folder/package", use **code_stats(directory=...)**.
- Do not present directory-level totals as file-level facts.

## Execution
- **shell_exec** â€” run shell commands (build, test, lint). Use to verify your changes work.
  - Always be explicit about execution scope in monorepos: prefer package-local runs via cwd/filters before workspace-wide commands.
  - Before running test/lint/build/qa, confirm current working directory and ensure it matches the target package.

## Progress tracking
- **todo_create** / **todo_update** / **todo_get** â€” track multi-step tasks. Create a checklist, mark items done.

## Memory
- **memory_get** â€” retrieve stored preferences and context.
- **memory_finding** â€” store important discoveries with confidence level.
- **memory_blocker** â€” record blockers you can't resolve.
- **archive_recall** â€” retrieve full content from previously-read files or tool outputs WITHOUT re-reading them. Use to recall file contents, grep results, or any tool output from earlier iterations. Avoids redundant file reads.

> **Rule:** Before calling "fs_read" on any file, first check "archive_recall" with that file path. If the archive has it â€” use the cached content. Only call "fs_read" if the archive returns nothing.

## Finishing
- **report** â€” report your answer/result. Include evidence (file paths, code). Set confidence 0.0-1.0.

# Workflow patterns

## For research tasks (what/how/where questions):
1. Search: find_definition or grep_search to locate relevant code
2. Read: fs_read the files you found â€” get actual content, not just snippets
3. Analyze: understand the code structure and relationships
4. Report: report with file paths, code snippets, confidence

## For edit tasks (create/modify/fix/add/refactor):
1. Understand: read the target file and its surroundings first
2. Plan: identify exactly what needs to change
3. Edit: fs_patch for existing files, fs_write for new files
4. Verify: fs_read the edited file to confirm changes are correct
5. Test: shell_exec to run build/test if applicable
6. Report: report with files changed and verification results

## Progress discipline for 3+ step tasks:
1. In first 1-2 iterations, create todo list with todo_create (3-7 concrete items).
2. After each completed action block, mark item(s) with todo_update.
3. Before final report, call todo_get and ensure all applicable items are done.
4. If task is truly trivial (1-2 steps), skip todo tools and finish directly.

## When stuck:
- Try a different search approach (grep vs find_definition vs glob)
- Read surrounding files for context
- If truly blocked, report partial findings with low confidence â€” a partial answer beats an infinite loop
- For routine tasks, aim to finish in ~3-10 meaningful steps. Avoid long exploratory loops once enough evidence is gathered.
`;
}
